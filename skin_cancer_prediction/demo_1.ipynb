{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4HGtRYHASpd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrHT_gHEQLUq",
        "outputId": "02247d23-1c12-4895-ac45-8f41d62139b4"
      },
      "source": [
        "cd drive/MyDrive/final_project/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/final_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSy3BARKQT-q"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from keras.applications import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4t1vcm4bxvH"
      },
      "source": [
        "model= Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "#model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrLetAYxfAz4"
      },
      "source": [
        "base_model= ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3ftKsvbfEpt",
        "outputId": "cf89c440-607b-43df-d80e-084164a07917"
      },
      "source": [
        "training_set = train_generator.flow_from_directory('./data/train',\n",
        "                                                 target_size = (224,224),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_generator.flow_from_directory('./data/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 64,\n",
        "                                            class_mode = 'categorical',\n",
        "                                            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2637 images belonging to 2 classes.\n",
            "Found 660 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je5WZwFzfHaw"
      },
      "source": [
        "model.compile(optimizer=optimizers.Adam(lr=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6vR4ehvfcA0"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learn_control = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=.5, min_lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puuwJvb4f9Zu",
        "outputId": "3b63bfdd-02a7-436f-b48e-2eaa3d28be95"
      },
      "source": [
        "model.fit_generator(generator=training_set,\n",
        "                            steps_per_epoch=training_set.samples//training_set.batch_size,\n",
        "                            validation_data=test_set,\n",
        "                            verbose=1,\n",
        "                            validation_steps=test_set.samples//test_set.batch_size,\n",
        "                            epochs=15,callbacks=[learn_control])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-5c3de3e04bc0>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.6412 - accuracy: 0.6607 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 2091s 51s/step - loss: 0.6412 - accuracy: 0.6607 - val_loss: 0.8586 - val_accuracy: 0.4375\n",
            "Epoch 2/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8150 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1804s 44s/step - loss: 0.3911 - accuracy: 0.8150 - val_loss: 1.6258 - val_accuracy: 0.4375\n",
            "Epoch 3/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8523 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1829s 45s/step - loss: 0.3139 - accuracy: 0.8523 - val_loss: 2.0111 - val_accuracy: 0.4375\n",
            "Epoch 4/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.8877 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1809s 44s/step - loss: 0.2536 - accuracy: 0.8877 - val_loss: 2.2176 - val_accuracy: 0.4375\n",
            "Epoch 5/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9157 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1807s 44s/step - loss: 0.2018 - accuracy: 0.9157 - val_loss: 1.4296 - val_accuracy: 0.4375\n",
            "Epoch 6/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9273 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1791s 44s/step - loss: 0.1707 - accuracy: 0.9273 - val_loss: 2.1579 - val_accuracy: 0.4375\n",
            "Epoch 7/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9475 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1803s 44s/step - loss: 0.1278 - accuracy: 0.9475 - val_loss: 0.8031 - val_accuracy: 0.4484\n",
            "Epoch 8/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9514 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1810s 44s/step - loss: 0.1274 - accuracy: 0.9514 - val_loss: 0.6362 - val_accuracy: 0.6672\n",
            "Epoch 9/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9549 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1819s 44s/step - loss: 0.1202 - accuracy: 0.9549 - val_loss: 2.3681 - val_accuracy: 0.4437\n",
            "Epoch 10/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9631 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1838s 45s/step - loss: 0.0935 - accuracy: 0.9631 - val_loss: 2.5916 - val_accuracy: 0.4422\n",
            "Epoch 11/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9631 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1798s 44s/step - loss: 0.0972 - accuracy: 0.9631 - val_loss: 1.4036 - val_accuracy: 0.5625\n",
            "Epoch 12/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9732 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1795s 44s/step - loss: 0.0806 - accuracy: 0.9732 - val_loss: 0.8188 - val_accuracy: 0.4609\n",
            "Epoch 13/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9837 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1809s 44s/step - loss: 0.0558 - accuracy: 0.9837 - val_loss: 5.5372 - val_accuracy: 0.4516\n",
            "Epoch 14/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9778 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1810s 44s/step - loss: 0.0587 - accuracy: 0.9778 - val_loss: 1.4550 - val_accuracy: 0.4203\n",
            "Epoch 15/15\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9872 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "41/41 [==============================] - 1814s 44s/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 1.0110 - val_accuracy: 0.4719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8b446aa550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaUj9C6wgBz3",
        "outputId": "7c79a0a4-8e20-49fb-8cb3-029c49aa6a42"
      },
      "source": [
        "test_set.reset()\n",
        "predictions = model.predict_generator(test_set, steps=test_set.samples/test_set.batch_size,verbose=1)\n",
        "y_pred= np.argmax(predictions, axis=1)\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-51bf124c0905>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "11/10 [================================] - 87s 8s/step\n",
            "[0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1\n",
            " 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuqmHt7xGNLu",
        "outputId": "f10619c2-f865-4282-b1b5-1300e5395cfc"
      },
      "source": [
        "y_test=np.array([])\n",
        "for i in range(360):\n",
        "    y_test=np.append(y_test,0)\n",
        "for i in range(300):\n",
        "    y_test=np.append(y_test,1)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFbowUYMIS4l",
        "outputId": "60b35733-cfc0-421f-e723-75426e377903"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix \n",
        "cm= confusion_matrix(y_test,y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[251 109]\n",
            " [245  55]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3e9yD1pIaBD"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb5gtRu0JEmv",
        "outputId": "f2fae7e5-9e2f-4e6d-fc8b-3eb5d9f2f082"
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4636363636363636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H9hK3_uKWpl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}